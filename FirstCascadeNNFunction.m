function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 29-Mar-2021 20:48:46.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 6xQ matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 2xQ matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [2;3.05;0;0.002;0.025;5.5];
x1_step1.gain = [0.0246305418719212;0.0476758045292014;0.0455580865603645;20.8333333333333;1.1142061281337;0.689655172413793];
x1_step1.ymin = -1;

% Layer 1
b1 = [1.9927978840243130154;1.7590476255255305116;0.93186938806838182092;0.21641282466559880193;0.28889522816461316035;-0.27322136401724117505;-0.80231742303174236053;-0.92234319842182665994;-1.4702319741160532196;1.3114284142025278701];
IW1_1 = [-0.85072075699760674183 -0.62337450212703138241 -1.0695223230548425164 -0.89618803687066039831 -0.030759541295096448632 -1.1707895577859570579;-0.27136490447392325187 -0.24457475184260363266 -1.2645794179466454121 -1.3685101788443239101 0.32576811071732930669 -0.32134992857151573054;-1.519100647974742202 0.47717020777762936268 1.3331187430574655828 -1.0805018491071425313 -0.63358960648235129742 1.7979737630888146249;-0.86663391410350243405 1.5938767945416871807 1.0240358581734734233 1.0676504171989842362 0.57238145098145276624 -0.038377012396072815448;-0.65239638192843119047 -0.50242184623283370204 0.35738480579903331158 -1.2279734329464258025 1.4241899404165454524 0.16857119689327387801;-1.360442921166148178 0.05249575058869753591 0.29374888073126476096 0.56024569226359932639 0.84589065006852992568 -1.0487157241590994161;-1.3232897258228450976 0.83947372367079964306 0.82273769853325895429 1.1927085622440858348 -0.86035330530855047559 2.2404877471125792532;-0.63360415356371191375 -0.5792617698823544492 1.8847514222983219323 -1.2952248239973094268 -0.56786060706326790815 -0.49869509280947055263;-0.97748044167689362993 -1.053054831136572167 0.9785862257379771556 0.89614951802611420018 0.6506373779030540927 0.41649041597848801555;0.75665022413534976931 0.79419905803504198261 -0.79780968064809121287 1.4082778449839765678 -0.3470115008508742882 1.9190589198514309555];

% Layer 2
b2 = [-1.1423939292721505545;0.26689237620267541873];
LW2_1 = [0.33778119175281723363 -0.98984655865971848954 1.4059308794230946926 0.75207400453084982672 0.50077027318485722862 -0.24879409952668624095 -0.84095436371175746881 0.23001845759208511266 -0.31522539687966061317 0.89273595227715696332;-0.14779838470664113936 0.9474306853049024868 -1.4276901985109893278 -0.9774365318547766357 -0.43735438703768103608 -0.63289619490665438573 2.162858689580040128 1.1022717592846769108 -1.1728705203526175183 -0.95189837005783495272];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},2); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
else
    a = iSoftmaxApplyCPU(n);
end
end
function a = iSoftmaxApplyCPU(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numerator = exp(n);
denominator = sum(numerator,1);
denominator(denominator == 0) = 1;
a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
nmax = max(n,[],1);
numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
denominator = sum(numerator,1);
a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
if (denominator == 0)
    a = numerator;
else
    a = numerator ./ denominator;
end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
